from gsplat2d.project_gaussians_cholesky import project_gaussians_cholesky
from gsplat2d.rasterize import rasterize_gaussians
from utils import *
import torch
import torch.nn as nn
import math
from optimizer import Adan

class LIG(nn.Module):
    def __init__(self, loss_type="L2", **kwargs):
        super().__init__()
        self.loss_type = loss_type
        self.init_num_points = kwargs["num_points"]
        self.H, self.W = kwargs["H"], kwargs["W"]

        self.n_scales = kwargs["n_scales"]
        self.allo_ratio = kwargs["allo_ratio"]
        self.level_models = []

        self.store_min = []
        self.store_max = []

        for s in range(self.n_scales):

            H = int(self.H * pow(2.0, -self.n_scales + s + 1))
            W = int(self.W * pow(2.0, -self.n_scales + s + 1))

            if s != self.n_scales - 1:
                num_points = int(kwargs["num_points"] * pow(2.0, (-self.n_scales + s + 1)*2) * self.allo_ratio)
            else:
                num_points = kwargs["num_points"]
                for i in range(s):
                    num_points -= int(kwargs["num_points"] * pow(2.0, (-self.n_scales + i + 1)*2) * self.allo_ratio)

            self.level_models.append(Gaussian2D(loss_type="L2", opt_type=kwargs['opt_type'], num_points=num_points, 
                                                   H=H, W=W, BLOCK_H=kwargs['BLOCK_H'], BLOCK_W=kwargs['BLOCK_W'],
                                                   device=kwargs['device'], lr=kwargs['lr']))

class Gaussian2D(nn.Module):
    def __init__(self, loss_type="L2", **kwargs):
        super().__init__()
        self.loss_type = loss_type
        self.init_num_points = kwargs["num_points"]
        self.H, self.W = kwargs["H"], kwargs["W"]

        self.B_SIZE = 16

        self.device = kwargs["device"]

        self.last_size = (self.H, self.W)

        w_init = torch.rand(self.init_num_points, 1, device=self.device) * self.W
        h_init = torch.rand(self.init_num_points, 1, device=self.device) * self.H
        self.means = nn.Parameter(torch.cat((w_init, h_init), dim=1))

        self._cholesky = nn.Parameter(torch.rand(self.init_num_points, 3, device=self.device))
        d = 3
        self._rgb_logits = nn.Parameter(torch.zeros(self.init_num_points, d, device=self.device))

        self.means.requires_grad = True
        self._cholesky.requires_grad = True
        self._rgb_logits.requires_grad = True

        if kwargs["opt_type"] == "adam":
            self.optimizer = torch.optim.Adam([
                {'params': self._rgb_logits, 'lr': kwargs["lr"]},
                {'params': self.means, 'lr': kwargs["lr"] * 2},
                {'params': self._cholesky, 'lr': kwargs["lr"] * 5},
            ])
        else:
            s = 1
            self.optimizer = Adan([
                {'params': self._rgb_logits, 'lr': kwargs["lr"] * 5 * s},
                {'params': self.means, 'lr': kwargs["lr"] * 2 * s},
                {'params': self._cholesky, 'lr': kwargs["lr"] * 5 * s},
            ],
                betas=(0.98, 0.92, 0.99),
                fused=True)
        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=70000, gamma=0.7)

    @property
    def cholesky(self):
        L11 = F.softplus(self._cholesky[:, 0])
        L21 = self._cholesky[:, 1]  # no softplus
        L22 = F.softplus(self._cholesky[:, 2])
        return torch.stack([L11, L21, L22], dim=1)

    @property
    def rgbs(self):
        return torch.sigmoid(self._rgb_logits)

    def forward(self):
        (
            xys,
            extents,
            conics,
            num_tiles_hit,
        ) = project_gaussians_cholesky(
            self.cholesky,
            self.means,
            self.H,
            self.W,
            self.B_SIZE,
        )
        out_img = rasterize_gaussians(
                xys,
                extents,
                conics,
                num_tiles_hit,
                self.rgbs,
                None,
                self.H,
                self.W,
                self.B_SIZE,
            )[0][..., :3]

        out_img = torch.clamp(out_img, 0, 1)
        out_img = out_img.view(-1, self.H, self.W, 3).permute(0, 3, 1, 2).contiguous()
        return {"render": out_img}

    def train_iter(self, gt_image):
        render_pkg = self.forward()
        image = render_pkg["render"]
        loss = loss_fn(image, gt_image, self.loss_type, lambda_value=0.7)
        loss.backward()
        with torch.no_grad():
            mse_loss = F.mse_loss(image, gt_image)
            psnr = 10 * math.log10(1.0 / mse_loss.item())
        self.optimizer.step()
        self.optimizer.zero_grad(set_to_none = True)

        self.scheduler.step()
        return loss, psnr
